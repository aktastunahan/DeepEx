{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "EpisodeStats = namedtuple(\"Stats\",[\"episode_lengths\", \"episode_rewards\"])\n",
    "\n",
    "def plot_cost_to_go_mountain_car(env, estimator, num_tiles=20):\n",
    "    x = np.linspace(env.observation_space.low[0], env.observation_space.high[0], num=num_tiles)\n",
    "    y = np.linspace(env.observation_space.low[1], env.observation_space.high[1], num=num_tiles)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    Z = np.apply_along_axis(lambda _: -np.max(estimator.predict(_)), 2, np.dstack([X, Y]))\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    surf = ax.plot_surface(X, Y, Z, rstride=1, cstride=1,\n",
    "                           cmap=matplotlib.cm.coolwarm, vmin=-1.0, vmax=1.0)\n",
    "    ax.set_xlabel('Position')\n",
    "    ax.set_ylabel('Velocity')\n",
    "    ax.set_zlabel('Value')\n",
    "    ax.set_title(\"Mountain \\\"Cost To Go\\\" Function\")\n",
    "    fig.colorbar(surf)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_value_function(V, title=\"Value Function\"):\n",
    "    \"\"\"\n",
    "    Plots the value function as a surface plot.\n",
    "    \"\"\"\n",
    "    min_x = min(k[0] for k in V.keys())\n",
    "    max_x = max(k[0] for k in V.keys())\n",
    "    min_y = min(k[1] for k in V.keys())\n",
    "    max_y = max(k[1] for k in V.keys())\n",
    "\n",
    "    x_range = np.arange(min_x, max_x + 1)\n",
    "    y_range = np.arange(min_y, max_y + 1)\n",
    "    X, Y = np.meshgrid(x_range, y_range)\n",
    "\n",
    "    # Find value for all (x, y) coordinates\n",
    "    Z_noace = np.apply_along_axis(lambda _: V[(_[0], _[1], False)], 2, np.dstack([X, Y]))\n",
    "    Z_ace = np.apply_along_axis(lambda _: V[(_[0], _[1], True)], 2, np.dstack([X, Y]))\n",
    "\n",
    "    def plot_surface(X, Y, Z, title):\n",
    "        fig = plt.figure(figsize=(20, 10))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        surf = ax.plot_surface(X, Y, Z, rstride=1, cstride=1,\n",
    "                               cmap=matplotlib.cm.coolwarm, vmin=-1.0, vmax=1.0)\n",
    "        ax.set_xlabel('Player Sum')\n",
    "        ax.set_ylabel('Dealer Showing')\n",
    "        ax.set_zlabel('Value')\n",
    "        ax.set_title(title)\n",
    "        ax.view_init(ax.elev, -120)\n",
    "        fig.colorbar(surf)\n",
    "        plt.show()\n",
    "\n",
    "    plot_surface(X, Y, Z_noace, \"{} (No Usable Ace)\".format(title))\n",
    "    plot_surface(X, Y, Z_ace, \"{} (Usable Ace)\".format(title))\n",
    "\n",
    "\n",
    "\n",
    "def plot_episode_stats(stats, smoothing_window=10, noshow=False):\n",
    "    # Plot the episode length over time\n",
    "    fig1 = plt.figure(figsize=(10,5))\n",
    "    plt.plot(stats.episode_lengths)\n",
    "    plt.xlabel(\"Episode\")\n",
    "    plt.ylabel(\"Episode Length\")\n",
    "    plt.title(\"Episode Length over Time\")\n",
    "    if noshow:\n",
    "        plt.close(fig1)\n",
    "    else:\n",
    "        plt.show(fig1)\n",
    "\n",
    "    # Plot the episode reward over time\n",
    "    fig2 = plt.figure(figsize=(10,5))\n",
    "    rewards_smoothed = pd.Series(stats.episode_rewards).rolling(smoothing_window, min_periods=smoothing_window).mean()\n",
    "    plt.plot(rewards_smoothed)\n",
    "    plt.xlabel(\"Episode\")\n",
    "    plt.ylabel(\"Episode Reward (Smoothed)\")\n",
    "    plt.title(\"Episode Reward over Time (Smoothed over window size {})\".format(smoothing_window))\n",
    "    if noshow:\n",
    "        plt.close(fig2)\n",
    "    else:\n",
    "        plt.show(fig2)\n",
    "\n",
    "    # Plot time steps and episode number\n",
    "    fig3 = plt.figure(figsize=(10,5))\n",
    "    plt.plot(np.cumsum(stats.episode_lengths), np.arange(len(stats.episode_lengths)))\n",
    "    plt.xlabel(\"Time Steps\")\n",
    "    plt.ylabel(\"Episode\")\n",
    "    plt.title(\"Episode per time step\")\n",
    "    if noshow:\n",
    "        plt.close(fig3)\n",
    "    else:\n",
    "        plt.show(fig3)\n",
    "\n",
    "    return fig1, fig2, fig3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import gym\n",
    "import itertools\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "if \"../\" not in sys.path:\n",
    "    sys.path.append(\"../\") \n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Environment import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "\n",
    "class Qlearning:\n",
    "    _qmatrix = None\n",
    "    _learn_rate = None\n",
    "    _discount_factor = None\n",
    "\n",
    "    def __init__(self,\n",
    "                 possible_states,\n",
    "                 possible_actions,\n",
    "                 initial_reward,\n",
    "                 learning_rate,\n",
    "                 discount_factor,\n",
    "                epsilon):\n",
    "        \"\"\"\n",
    "        Initialise the q learning class with an initial matrix and the parameters for learning.\n",
    "\n",
    "        :param possible_states: list of states the agent can be in\n",
    "        :param possible_actions: list of actions the agent can perform\n",
    "        :param initial_reward: the initial Q-values to be used in the matrix\n",
    "        :param learning_rate: the learning rate used for Q-learning\n",
    "        :param discount_factor: the discount factor used for Q-learning\n",
    "        \"\"\"\n",
    "        # Initialize the matrix with Q-values\n",
    "        init_data = [[float(initial_reward) for _ in possible_states]\n",
    "                     for _ in possible_actions]\n",
    "        self._qmatrix = pd.DataFrame(data=init_data,\n",
    "                                     index=possible_actions,\n",
    "                                     columns=possible_states)\n",
    "        self._qmatrix[\"count\"] = 0\n",
    "\n",
    "        # Save the parameters\n",
    "        self._learn_rate = learning_rate\n",
    "        self._discount_factor = discount_factor\n",
    "        self.initial_reward = initial_reward\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def get_best_action(self, state, actions,policy=True):\n",
    "        \"\"\"\n",
    "        Retrieve the action resulting in the highest Q-value for a given state.\n",
    "\n",
    "        :param state: the state for which to determine the best action\n",
    "        :return: the best action from the given state\n",
    "        \"\"\"\n",
    "        \n",
    "        for x in actions:\n",
    "            tag = x.split(\"!@!\")[0]\n",
    "            qv = len(actions)-len([y for y in actions if y.split(\"!@!\")[0]==tag])\n",
    "            qv = self.initial_reward+(self.initial_reward*qv)\n",
    "            #self.checkAction(x,Qvalue=qv)\n",
    "            self.checkAction(x)\n",
    "        \n",
    "        self.checkState(state,availableActions=actions)\n",
    "        \n",
    "        if policy:\n",
    "            if random.random()>self.epsilon:\n",
    "                # Return the action (index) with maximum Q-value\n",
    "                return self._qmatrix[[state]].idxmax().iloc[0]\n",
    "            else:\n",
    "                ac = random.choice(self._qmatrix.index)\n",
    "                return ac\n",
    "        else:\n",
    "            return self._qmatrix.loc[actions][[state]].idxmax().iloc[0]\n",
    "    \n",
    "    def checkState(self,state,Qvalue=-999999,availableActions=None):\n",
    "        if Qvalue==-999999:\n",
    "            Qvalue=self.initial_reward\n",
    "        if state not in self._qmatrix.columns:\n",
    "            #print(\"Adding State\",state)\n",
    "            if availableActions!=None:\n",
    "                if type(availableActions)==list:\n",
    "                    self._qmatrix[state] = -999999\n",
    "                    self._qmatrix.loc[availableActions,state] = float(Qvalue)\n",
    "            else:\n",
    "                self._qmatrix[state] = float(Qvalue)\n",
    "            \n",
    "    def checkAction(self,action,Qvalue=-999999):\n",
    "        if Qvalue==-999999:\n",
    "            Qvalue=self.initial_reward\n",
    "        if action not in self._qmatrix.index:\n",
    "            #print(\"Adding Action\",action)\n",
    "            self._qmatrix.loc[action] = float(Qvalue)\n",
    "            self._qmatrix.loc[action,\"count\"] = 0\n",
    "\n",
    "    def update_model(self, state, action, reward, next_state,next_actions):\n",
    "        \"\"\"\n",
    "        Update the Q-values for a given observation.\n",
    "\n",
    "        :param state: The state the observation started in\n",
    "        :param action: The action taken from that state\n",
    "        :param reward: The reward retrieved from taking action from state\n",
    "        :param next_state: The resulting next state of taking action from state\n",
    "        \"\"\"\n",
    "        self.checkAction(action)\n",
    "        self.checkState(state)\n",
    "        \n",
    "        # Update q_value for a state-action pair Q(s,a):\n",
    "        # Q(s,a) = Q(s,a) + α( r + γmaxa' Q(s',a') - Q(s,a) )\n",
    "        #print(\"Updating Temporal Difference\")\n",
    "        q_sa = self._qmatrix.loc[action, state]\n",
    "        if len(next_actions)>=1:\n",
    "            max_q_sa_next = self._qmatrix.loc[self.get_best_action(next_state,next_actions,policy=False), next_state]\n",
    "            r = reward\n",
    "            alpha = self._learn_rate\n",
    "            gamma = self._discount_factor*np.exp(-0.1*(len(next_actions)-1))\n",
    "            # Do the computation\n",
    "            new_q_sa = q_sa + alpha * (r + gamma * max_q_sa_next - q_sa)\n",
    "            if type(new_q_sa)==pd.core.series.Series:\n",
    "                new_q_sa = new_q_sa.values[0]\n",
    "            #print(\"newq=\",new_q_sa)\n",
    "            self._qmatrix.loc[action, state] = new_q_sa\n",
    "            return 1\n",
    "        #print(\"updated\")\n",
    "        else:\n",
    "            max_q_sa_next = -999999\n",
    "            r = reward\n",
    "            alpha = self._learn_rate\n",
    "            gamma = self._discount_factor*np.exp(-0.1*(0-1))\n",
    "            # Do the computation\n",
    "            new_q_sa = q_sa + alpha * (r + gamma * max_q_sa_next - q_sa)\n",
    "            if type(new_q_sa)==pd.core.series.Series:\n",
    "                new_q_sa = new_q_sa.values[0]\n",
    "            #print(\"newq=\",new_q_sa)\n",
    "            self._qmatrix.loc[action, state] = new_q_sa\n",
    "            return -1\n",
    "        \n",
    "from apted import APTED\n",
    "from apted.helpers import Tree\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, os\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "from bs4 import BeautifulSoup\n",
    "import bs4\n",
    "#from collections import defaultdict\n",
    "\n",
    "from collections import OrderedDict, Callable\n",
    "\n",
    "class DefaultOrderedDict(OrderedDict):\n",
    "    # Source: http://stackoverflow.com/a/6190500/562769\n",
    "    def __init__(self, default_factory=None, *a, **kw):\n",
    "        if (default_factory is not None and\n",
    "           not isinstance(default_factory, Callable)):\n",
    "            raise TypeError('first argument must be callable')\n",
    "        OrderedDict.__init__(self, *a, **kw)\n",
    "        self.default_factory = default_factory\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        try:\n",
    "            return OrderedDict.__getitem__(self, key)\n",
    "        except KeyError:\n",
    "            return self.__missing__(key)\n",
    "\n",
    "    def __missing__(self, key):\n",
    "        if self.default_factory is None:\n",
    "            raise KeyError(key)\n",
    "        self[key] = value = self.default_factory()\n",
    "        return value\n",
    "\n",
    "    def __reduce__(self):\n",
    "        if self.default_factory is None:\n",
    "            args = tuple()\n",
    "        else:\n",
    "            args = self.default_factory,\n",
    "        return type(self), args, None, None, self.items()\n",
    "\n",
    "    def copy(self):\n",
    "        return self.__copy__()\n",
    "\n",
    "    def __copy__(self):\n",
    "        return type(self)(self.default_factory, self)\n",
    "\n",
    "    def __deepcopy__(self, memo):\n",
    "        import copy\n",
    "        return type(self)(self.default_factory,\n",
    "                          copy.deepcopy(self.items()))\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'OrderedDefaultDict(%s, %s)' % (self.default_factory,\n",
    "                                               OrderedDict.__repr__(self))\n",
    "\n",
    "\n",
    "\n",
    "def defaultVal():\n",
    "    return [[],0]\n",
    "\n",
    "def makeTree(S):\n",
    "    S = S.strip()\n",
    "    S = S.replace(\"\\n\",\"\")\n",
    "    #S = S.replace(\" \",\"\")\n",
    "    S = S.replace(\"\\t\",\"\")\n",
    "    S = S.replace(\"\\r\",\"\")\n",
    "    soup = BeautifulSoup(S, \"html.parser\")\n",
    "    return soup\n",
    "\n",
    "def recursiveChildBfs(bs):\n",
    "    root = bs\n",
    "    stack = [root]\n",
    "    count=0\n",
    "    parrent = [None]\n",
    "    while len(stack) != 0:\n",
    "        node = stack.pop(0)\n",
    "        pnode = parrent.pop(0)\n",
    "        if node is not bs:\n",
    "            if node.name!=None:\n",
    "                yield node.name+\"~\"+str(count),pnode\n",
    "            else:\n",
    "                yield node.name,pnode\n",
    "        if hasattr(node, 'children'):\n",
    "            for child in node.children:\n",
    "                stack.append(child)\n",
    "                parrent.append(node.name+\"~\"+str(count))\n",
    "        count+=1\n",
    "\n",
    "def visit(tagdict,c,tree):\n",
    "    tree+=\"{\"\n",
    "    tree+=c.split(\"~\")[0]\n",
    "    for i in tagdict[c][0]:\n",
    "        tree = visit(tagdict,i,tree)\n",
    "        tree+=\"}\"\n",
    "    return tree        \n",
    "\n",
    "def generateTree(S):\n",
    "    html = makeTree(S)\n",
    "    tagdict = DefaultOrderedDict(defaultVal)\n",
    "    for c,p in recursiveChildBfs(html):\n",
    "        if c!=None:\n",
    "            tagdict[p][0].append(c)\n",
    "            tagdict[p][1]+=1\n",
    "\n",
    "\n",
    "    tree = \"{\"\n",
    "    for x,y in zip(list(tagdict.keys())[1::],list(tagdict.values())[1::]):\n",
    "        tree+=x.split(\"~\")[0]\n",
    "        for c in y[0]:\n",
    "            #tree+=\"{\"\n",
    "            #tree+=c\n",
    "            tree = visit(tagdict,c,tree)\n",
    "            tree+=\"}\"\n",
    "        tree+=\"}\"\n",
    "        break\n",
    "    nNodes = 0\n",
    "    for x in tagdict.keys():\n",
    "        nNodes+=tagdict[x][1]\n",
    "    return tree,nNodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "env = webEnv(url=\"http://192.168.1.68/timeclock/\",BaseURL=\"http://192.168.1.68/timeclock\",actionWait=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import json\n",
    "from threading import Thread\n",
    "\n",
    "CLOSE=False\n",
    "\n",
    "def save_stateMap(obj, name):\n",
    "    with open(name,\"w\") as dd:\n",
    "        dd.write(json.dumps(obj))\n",
    "\n",
    "def load_stateMap(name):\n",
    "    with open(name) as json_file:\n",
    "        data = defaultdict(factory)\n",
    "        data2 = json.load(json_file)\n",
    "        data.update(data2)\n",
    "    return data\n",
    "\n",
    "def factory():\n",
    "    return {\"src\":\"\",\"edges\":[],\"url\":\"\",\"start\":0}\n",
    "\n",
    "def makeGraph(stateMap,output):\n",
    "    statesfile = [file.split(\"/\")[-1].split(\".html\")[0] for file in glob.glob(output+\"/*.html\")]\n",
    "    with open(os.path.join(output,\"data.js\"),\"w\") as jsonwriter:\n",
    "        C = []\n",
    "        for x in stateMap.keys():\n",
    "            stateMap[x][\"edges\"] = [{\"action\":y[\"action\"],\"state\":y[\"state\"]} for y in stateMap[x][\"edges\"] if y[\"state\"] in statesfile]\n",
    "            C.append(stateMap[x])\n",
    "        C.sort(key=lambda x:x[\"start\"],reverse=True)\n",
    "        jsonwriter.write(\"let data = \")\n",
    "        jsonwriter.write(json.dumps(C))\n",
    "\n",
    "def q_learning(env, num_episodes,sleep=0,matrix=None,statemap=None,_epsilon=0.2,onlyperform=False,output=\"./Q_Result\",timebound=True,activity_time=None):\n",
    "    global CLOSE\n",
    "    #stats = EpisodeStats(\n",
    "    #    episode_lengths=np.zeros(num_episodes),\n",
    "    #    episode_rewards=np.zeros(num_episodes))    \n",
    "    \n",
    "    env.reset()\n",
    "    state = env.get_Actions_OR_state()\n",
    "    state = chash.md5(state)\n",
    "    \n",
    "    Qlearn = Qlearning(possible_states = [state],\n",
    "                      possible_actions = env.get_Actions_OR_state(True),\n",
    "                      initial_reward = 500,\n",
    "                      learning_rate = 1,\n",
    "                      discount_factor = 0.9,\n",
    "                      epsilon=_epsilon)\n",
    "    \n",
    "    if type(matrix)==pd.core.frame.DataFrame:\n",
    "        Qlearn._qmatrix = matrix\n",
    "        #onlyperform = True\n",
    "    display(Qlearn._qmatrix)\n",
    "    rewardlist = [\"http://192.168.1.68/timeclock/admin/groupdelete.php\",\"http://192.168.1.68/timeclock/admin/index.php\"]\n",
    "    curl = \"\"\n",
    "    \n",
    "    #-=-=-=-=makedir=-=-=-=\n",
    "    stateMap = defaultdict(factory)\n",
    "    if os.path.exists(output):\n",
    "        if statemap==None:\n",
    "            shutil.rmtree(output)\n",
    "            os.mkdir(output)\n",
    "        else:\n",
    "            stateMap = statemap\n",
    "    else:\n",
    "        os.mkdir(output)\n",
    "    for code in os.listdir(\"./graphView/\"):\n",
    "        shutil.copyfile(os.path.join(\"./graphView/\",code),os.path.join(output,code))\n",
    "    #-=-=-==-=-=-=-=-=-=-=-\n",
    "    if timebound:\n",
    "        def some_task():\n",
    "            global CLOSE\n",
    "            time.sleep(activity_time)\n",
    "            CLOSE=True\n",
    "        t = Thread(target=some_task)\n",
    "        t.start()\n",
    "    \n",
    "    \n",
    "    startstate = chash.md5(env.get_Actions_OR_state())\n",
    "    i_episode=0\n",
    "    while(True):\n",
    "        print(\"EPISODE= \",i_episode)\n",
    "        if timebound:\n",
    "            if CLOSE:\n",
    "                break\n",
    "        else:\n",
    "            if i_episode>num_episodes:\n",
    "                break\n",
    "    #for i_episode in tqdm(range(num_episodes)):\n",
    "        Qlearn._qmatrix.to_csv(\"./Q-table\")\n",
    "        save_stateMap(stateMap,\"Q.map\")\n",
    "        env.reset(curl)\n",
    "        curl = \"\"\n",
    "        state = chash.md5(env.get_Actions_OR_state())\n",
    "        state_actions = env.get_Actions_OR_state(True)\n",
    "        prev_action = \"\"\n",
    "        actionlist = []\n",
    "        #startstate = state\n",
    "        for t in itertools.count():\n",
    "            urlbefore = \"\"\n",
    "            #=-=--=-=-STATE GRAPH-=-=-=-=-\n",
    "            env.website.save_screenshot(os.path.join(output,state+\".png\"))\n",
    "            with open(os.path.join(output,state+\".html\"),\"w\") as htmlwriter:\n",
    "                htmlwriter.write(env.website.page_source)\n",
    "            #-=--=-=-=--=-=-=-=-=-=-=-=-=\n",
    "            \n",
    "            # Take a step\n",
    "            action = Qlearn.get_best_action(state,state_actions,policy=False)\n",
    "            #print(\"selected action \",action,\"episode \",i_episode)\n",
    "            elem = env.reverseEngineerAction(action)\n",
    "            \n",
    "            done=False\n",
    "            reward = -99999\n",
    "            if elem!=None:\n",
    "                curl = env.website.current_url\n",
    "                status,done = env.step(elem,login_url=[\"http://192.168.1.68/timeclock/login.php\",\n",
    "                                                      \"http://192.168.1.68/timeclock/login_reports.php\",\n",
    "                                                      \"http://192.168.1.68/timeclock/login_admin.php\"],\n",
    "                                       username=\"admin\",password=\"admin\",\n",
    "                                       depth=100)\n",
    "                if status:\n",
    "                    urlbefore = curl\n",
    "                    currenturl = None\n",
    "                    breakcount = 0\n",
    "                    while currenturl==None and breakcount<5:\n",
    "                        try:\n",
    "                            currenturl = env.website.current_url\n",
    "                            breakcount=6\n",
    "                        except:\n",
    "                            breakcount+=1\n",
    "                            continue\n",
    "                    if env.BaseURL in env.website.current_url:\n",
    "                        #if env.website.current_url in rewardlist:\n",
    "                        #    reward = 500\n",
    "                        #    done=True\n",
    "                        #    rewardlist.remove(env.website.current_url)\n",
    "                        #else:\n",
    "                        #    #reward = -1\n",
    "                        #    Qlearn._qmatrix.loc[action,\"count\"]+=1\n",
    "                        #    reward = 1/np.sum(Qlearn._qmatrix.loc[action,\"count\"])\n",
    "                        Qlearn._qmatrix.loc[action,\"count\"]+=1\n",
    "                        reward = 1/np.sum(Qlearn._qmatrix.loc[action,\"count\"])\n",
    "                        curl = \"\"\n",
    "                    else:\n",
    "                        reward = -999999999999\n",
    "                        done = True\n",
    "                else:\n",
    "                    print(\"status is none-=-\",elem.get_attribute(\"outerHTML\"))\n",
    "                \n",
    "            else:\n",
    "                print(\"none---\",len(state_actions),\"selected=\",action)\n",
    "            if reward==-999999999999:\n",
    "                next_state = state\n",
    "                next_state_actions = state_actions\n",
    "            else:\n",
    "                S = env.get_Actions_OR_state()\n",
    "                if S=='':\n",
    "                    S = env.website.page_source\n",
    "                    S,nodes = generateTree(S)\n",
    "                    \n",
    "                next_state = chash.md5(S)\n",
    "                next_state_actions = env.get_Actions_OR_state(True)\n",
    "                env.website.save_screenshot(os.path.join(output,next_state+\".png\"))\n",
    "                with open(os.path.join(output,next_state+\".html\"),\"w\") as htmlwriter:\n",
    "                    htmlwriter.write(env.website.page_source)\n",
    "\n",
    "            if not onlyperform:\n",
    "                if Qlearn.update_model(state, action, reward, next_state,next_state_actions)==-1:\n",
    "                    done=True\n",
    "                #-=-=-=-=makingGraph=-=-=-=-\n",
    "                stateMap[state][\"src\"]=state\n",
    "                stateMap[state][\"edges\"].append({\"action\":action,\"state\":next_state})\n",
    "                if state==startstate:\n",
    "                    stateMap[state][\"start\"] = 1\n",
    "                stateMap[state][\"url\"] = urlbefore\n",
    "                #-==-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "            prev_action = action\n",
    "\n",
    "            # Update statistics\n",
    "            #if not onlyperform:\n",
    "            #    stats.episode_rewards[i_episode] += reward\n",
    "            #    stats.episode_lengths[i_episode] = t\n",
    "\n",
    "            if done==True:\n",
    "                break\n",
    "\n",
    "            state = next_state\n",
    "            state_actions = next_state_actions\n",
    "        #print(actionlist)\n",
    "        i_episode+=1\n",
    "    makeGraph(stateMap,output)\n",
    "    #return stats,Qlearn,stateMap\n",
    "    return 0,Qlearn,stateMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2a37943c3d7117b3f16609f866c1e35f</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>input!@!employee_passwd!@!nan!@!nan</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>input!@!left_notes!@!nan!@!nan</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>input!@!remember_me!@!1!@!nan</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>input!@!submit_button!@!Submit!@!nan</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>a!@!nan!@!nan!@!http://192.168.1.68/timeclock/index.php</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>a!@!nan!@!nan!@!http://www.historychannel.com/tdih</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>a!@!nan!@!nan!@!http://192.168.1.68/timeclock/login.php</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>a!@!nan!@!nan!@!http://192.168.1.68/timeclock/reports/index.php</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>a!@!nan!@!nan!@!http://192.168.1.68/timeclock/punchclock/menu.php</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>a!@!nan!@!nan!@!http://httpd.apache.org/</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>a!@!nan!@!nan!@!http://mysql.org/</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>a!@!nan!@!nan!@!http://php.net/</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>a!@!nan!@!nan!@!http://timeclock.sourceforge.net/</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>select!@!left_fullname!@!nan!@!nan</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>select!@!left_inout!@!nan!@!nan</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    2a37943c3d7117b3f16609f866c1e35f  \\\n",
       "input!@!employee_passwd!@!nan!@!nan                                            500.0   \n",
       "input!@!left_notes!@!nan!@!nan                                                 500.0   \n",
       "input!@!remember_me!@!1!@!nan                                                  500.0   \n",
       "input!@!submit_button!@!Submit!@!nan                                           500.0   \n",
       "a!@!nan!@!nan!@!http://192.168.1.68/timeclock/i...                             500.0   \n",
       "a!@!nan!@!nan!@!http://www.historychannel.com/tdih                             500.0   \n",
       "a!@!nan!@!nan!@!http://192.168.1.68/timeclock/l...                             500.0   \n",
       "a!@!nan!@!nan!@!http://192.168.1.68/timeclock/r...                             500.0   \n",
       "a!@!nan!@!nan!@!http://192.168.1.68/timeclock/p...                             500.0   \n",
       "a!@!nan!@!nan!@!http://httpd.apache.org/                                       500.0   \n",
       "a!@!nan!@!nan!@!http://mysql.org/                                              500.0   \n",
       "a!@!nan!@!nan!@!http://php.net/                                                500.0   \n",
       "a!@!nan!@!nan!@!http://timeclock.sourceforge.net/                              500.0   \n",
       "select!@!left_fullname!@!nan!@!nan                                             500.0   \n",
       "select!@!left_inout!@!nan!@!nan                                                500.0   \n",
       "\n",
       "                                                    count  \n",
       "input!@!employee_passwd!@!nan!@!nan                     0  \n",
       "input!@!left_notes!@!nan!@!nan                          0  \n",
       "input!@!remember_me!@!1!@!nan                           0  \n",
       "input!@!submit_button!@!Submit!@!nan                    0  \n",
       "a!@!nan!@!nan!@!http://192.168.1.68/timeclock/i...      0  \n",
       "a!@!nan!@!nan!@!http://www.historychannel.com/tdih      0  \n",
       "a!@!nan!@!nan!@!http://192.168.1.68/timeclock/l...      0  \n",
       "a!@!nan!@!nan!@!http://192.168.1.68/timeclock/r...      0  \n",
       "a!@!nan!@!nan!@!http://192.168.1.68/timeclock/p...      0  \n",
       "a!@!nan!@!nan!@!http://httpd.apache.org/                0  \n",
       "a!@!nan!@!nan!@!http://mysql.org/                       0  \n",
       "a!@!nan!@!nan!@!http://php.net/                         0  \n",
       "a!@!nan!@!nan!@!http://timeclock.sourceforge.net/       0  \n",
       "select!@!left_fullname!@!nan!@!nan                      0  \n",
       "select!@!left_inout!@!nan!@!nan                         0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPISODE=  0\n",
      "EPISODE=  1\n",
      "EPISODE=  2\n",
      "EPISODE=  3\n",
      "EPISODE=  4\n",
      "EPISODE=  5\n",
      "EPISODE=  6\n",
      "EPISODE=  7\n",
      "EPISODE=  8\n",
      "none--- 15 selected= a!@!nan!@!nan!@!http://mysql.org/\n",
      "none--- 15 selected= a!@!nan!@!nan!@!http://php.net/\n",
      "none--- 15 selected= a!@!nan!@!nan!@!http://timeclock.sourceforge.net/\n",
      "EPISODE=  9\n",
      "EPISODE=  10\n",
      "EPISODE=  11\n",
      "none--- 12 selected= a!@!nan!@!nan!@!http://mysql.org/\n",
      "none--- 12 selected= a!@!nan!@!nan!@!http://php.net/\n",
      "none--- 12 selected= a!@!nan!@!nan!@!http://timeclock.sourceforge.net/\n",
      "EPISODE=  12\n",
      "EPISODE=  13\n",
      "EPISODE=  14\n",
      "EPISODE=  15\n",
      "EPISODE=  16\n",
      "EPISODE=  17\n",
      "EPISODE=  18\n",
      "EPISODE=  19\n",
      "EPISODE=  20\n",
      "EPISODE=  21\n",
      "EPISODE=  22\n",
      "EPISODE=  23\n",
      "EPISODE=  24\n",
      "EPISODE=  25\n",
      "EPISODE=  26\n",
      "none--- 15 selected= a!@!nan!@!nan!@!http://mysql.org/\n",
      "none--- 15 selected= a!@!nan!@!nan!@!http://php.net/\n",
      "none--- 15 selected= a!@!nan!@!nan!@!http://timeclock.sourceforge.net/\n",
      "EPISODE=  27\n"
     ]
    }
   ],
   "source": [
    "stats,matrix,stateMap=q_learning(env, 2,timebound=True,activity_time=600)\n",
    "#stats,matrix,stateMap=q_learning(env, 10,matrix=pd.read_csv(\"./Q-table5\",index_col=0),statemap=stateMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for x in stateMap.keys():\n",
    "    stateMap[x][\"edges\"] = [{\"action\":y[\"action\"],\"state\":y[\"state\"]} for y in stateMap[x][\"edges\"] if y[\"state\"] in stateMap.keys()]\n",
    "for x in stateMap.keys():\n",
    "    for y in stateMap[x][\"edges\"]:\n",
    "        if \"d41d8cd98f00b204e9800998ecf8427e\" in y[\"state\"]:\n",
    "            print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_episode_stats(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(matrix._qmatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_stateMap(stateMap,\"timeclock.map\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_stateMap(\"timeclock.map\")\n",
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
